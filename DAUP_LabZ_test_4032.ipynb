{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nSYdfIHhtRTQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/diabetes_data_upload.csv\")\n"
      ],
      "metadata": {
        "id": "DLfyEulLtS3M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "        label_encoders[column] = le"
      ],
      "metadata": {
        "id": "OxZXamistWER"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"class\"])\n",
        "y = df[\"class\"]"
      ],
      "metadata": {
        "id": "m_I2b2ZHtYZK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "rTtzdQ0xta6f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    fnr = cm[1, 0] / (cm[1, 0] + cm[1, 1])  # Type II Error (False Negatives)\n",
        "    fpr = cm[0, 1] / (cm[0, 0] + cm[0, 1])  # Type I Error (False Positives)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"False Negative Rate\": fnr,\n",
        "        \"False Positive Rate\": fpr\n",
        "    }"
      ],
      "metadata": {
        "id": "EV__zgQdtb98"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOOZ8RgqtfwI",
        "outputId": "4d0507f7-71ff-4ea5-84b4-9fd487d26df5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy  Precision    Recall  False Negative Rate  \\\n",
            "Logistic Regression  0.942308   0.983333  0.921875             0.078125   \n",
            "Decision Tree        0.990385   1.000000  0.984375             0.015625   \n",
            "Random Forest        0.990385   1.000000  0.984375             0.015625   \n",
            "SVM                  0.615385   0.615385  1.000000             0.000000   \n",
            "KNN                  0.932692   0.983051  0.906250             0.093750   \n",
            "Gradient Boosting    0.990385   1.000000  0.984375             0.015625   \n",
            "\n",
            "                     False Positive Rate  \n",
            "Logistic Regression                0.025  \n",
            "Decision Tree                      0.000  \n",
            "Random Forest                      0.000  \n",
            "SVM                                1.000  \n",
            "KNN                                0.025  \n",
            "Gradient Boosting                  0.000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_preds = models[\"Logistic Regression\"].predict(X_test)\n",
        "diabetic_indices = (y_test == 1)\n",
        "correctly_classified = (logistic_preds == y_test) & diabetic_indices\n",
        "misclassified = (~correctly_classified) & diabetic_indices\n",
        "\n",
        "correct_ages = X_test.loc[correctly_classified, \"Age\"]\n",
        "misclassified_ages = X_test.loc[misclassified, \"Age\"]\n",
        "\n",
        "mean_correct = np.mean(correct_ages)\n",
        "mean_misclassified = np.mean(misclassified_ages)\n",
        "std_correct = np.std(correct_ages, ddof=1)\n",
        "std_misclassified = np.std(misclassified_ages, ddof=1)\n",
        "n_correct = len(correct_ages)\n",
        "n_misclassified = len(misclassified_ages)\n",
        "\n",
        "std_error = np.sqrt((std_correct**2 / n_correct) + (std_misclassified**2 / n_misclassified))\n",
        "z_stat = (mean_correct - mean_misclassified) / std_error\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "print(f\"Z-Test for Age Difference: Z-Score = {z_stat:.2f}, P-Value = {p_value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2XU58A2th0C",
        "outputId": "ea119fb8-9d9e-4a70-e17a-c3fceb9a9b02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-Test for Age Difference: Z-Score = 1.41, P-Value = 0.1592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fnr_svm = results[\"SVM\"][\"False Negative Rate\"]\n",
        "fnr_logistic = results[\"Logistic Regression\"][\"False Negative Rate\"]\n",
        "n_svm = y_test.sum()\n",
        "n_logistic = y_test.sum()\n",
        "\n",
        "std_error_fnr = np.sqrt((fnr_svm * (1 - fnr_svm) / n_svm) + (fnr_logistic * (1 - fnr_logistic) / n_logistic))\n",
        "z_stat_fnr = (fnr_svm - fnr_logistic) / std_error_fnr\n",
        "p_value_fnr = 2 * (1 - norm.cdf(abs(z_stat_fnr)))\n",
        "\n",
        "print(f\"Z-Test for False Negative Rate: Z-Score = {z_stat_fnr:.2f}, P-Value = {p_value_fnr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpQpQewDtj7c",
        "outputId": "d340de8a-8a24-4f4a-f75b-5569a7e11632"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-Test for False Negative Rate: Z-Score = -2.33, P-Value = 0.0199\n"
          ]
        }
      ]
    }
  ]
}